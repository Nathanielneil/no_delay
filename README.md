# å¤šæ— äººæœºåˆ†å±‚å¼ºåŒ–å­¦ä¹ åä½œæ¢ç´¢ç³»ç»Ÿ

åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„å¤šæ™ºèƒ½ä½“æ— äººæœºé›†ç¾¤åä½œæ¢ç´¢ä¸åŒºåŸŸè¦†ç›–è§£å†³æ–¹æ¡ˆï¼Œé‡‡ç”¨åˆ†å±‚å¼ºåŒ–å­¦ä¹ æ¶æ„ï¼Œæ”¯æŒGPUå¹¶è¡Œè®­ç»ƒã€‚

## ğŸš€ ä¸»è¦ç‰¹æ€§

- **åˆ†å±‚å¼ºåŒ–å­¦ä¹ æ¶æ„**: é«˜å±‚ç­–ç•¥è´Ÿè´£åŒºåŸŸåˆ†é…å’Œåä½œåè°ƒï¼Œä½å±‚ç­–ç•¥è´Ÿè´£é£è¡Œæ§åˆ¶
- **å¤šæ™ºèƒ½ä½“åä½œ**: æ”¯æŒå¤šæ— äººæœºçš„ååŒæ¢ç´¢å’Œé¿å…é‡å¤è¦†ç›–
- **GPUå¹¶è¡Œè®­ç»ƒ**: åŸºäºRayæ¡†æ¶çš„åˆ†å¸ƒå¼è®­ç»ƒï¼Œæ”¯æŒå¤šGPUåŠ é€Ÿ
- **å®æ—¶å¯è§†åŒ–**: æä¾›è®­ç»ƒè¿‡ç¨‹å’Œä»»åŠ¡æ‰§è¡Œçš„å®æ—¶ç›‘æ§
- **ROSé›†æˆ**: æ”¯æŒä¸Gazebo/PX4ä»¿çœŸç¯å¢ƒå’Œå®é™…æ— äººæœºçš„é›†æˆ
- **æ¨¡å—åŒ–è®¾è®¡**: æ˜“äºæ‰©å±•å’Œå®šåˆ¶çš„æ¶æ„è®¾è®¡

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **CPU**: 8æ ¸ä»¥ä¸Šæ¨è
- **å†…å­˜**: 16GBä»¥ä¸Š
- **GPU**: NVIDIA GPU (å¯é€‰ï¼Œç”¨äºåŠ é€Ÿè®­ç»ƒ)
- **å­˜å‚¨**: 20GBå¯ç”¨ç©ºé—´

### è½¯ä»¶ç¯å¢ƒ
- Python 3.7+
- CUDA 11.0+ (å¦‚ä½¿ç”¨GPU)
- ROS Melodic/Noetic (å¯é€‰ï¼Œç”¨äºå®æœºéƒ¨ç½²)

## ğŸ› ï¸ å®‰è£…æŒ‡å—

### 1. å…‹éš†é¡¹ç›®
```bash
git clone https://github.com/your-username/multi-drone-hrl.git
cd multi-drone-hrl
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
conda create -n drone_rl python=3.8
conda activate drone_rl
```

### 3. å®‰è£…ä¾èµ–
```bash
# åŸºç¡€ä¾èµ–
pip install torch torchvision torchaudio
pip install ray[rllib] ray[tune]
pip install gym numpy matplotlib seaborn pandas
pip install pyyaml opencv-python

# ROSä¾èµ– (å¯é€‰)
# sudo apt-get install ros-noetic-desktop-full
# pip install rospy rospkg
```

### 4. GPUæ”¯æŒ (å¯é€‰)
```bash
# æ£€æŸ¥CUDAç‰ˆæœ¬
nvidia-smi

# å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## ğŸƒâ€â™‚ï¸ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè®¾ç½®
```bash
python quick_start.py --mode setup
```

### 2. å¼€å§‹è®­ç»ƒ
```bash
# åŸºç¡€è®­ç»ƒ (CPU)
python quick_start.py --mode train --workers 4 --iterations 1000

# GPUåŠ é€Ÿè®­ç»ƒ
python quick_start.py --mode train --gpus 1 --workers 4 --iterations 2000

# è‡ªå®šä¹‰é…ç½®è®­ç»ƒ
python quick_start.py --mode train --config configs/custom.yaml
```

### 3. æ¨¡å‹è¯„ä¼°
```bash
python quick_start.py --mode eval --model checkpoints/best_model.pkl --eval_episodes 100
```

### 4. æ¼”ç¤ºå¯è§†åŒ–
```bash
# å®æ—¶å¯è§†åŒ–
python quick_start.py --mode demo

# ä¿å­˜åŠ¨ç”»è§†é¢‘
python quick_start.py --mode demo --save_animation
```

## ğŸ“Š æ ¸å¿ƒæ¶æ„

### åˆ†å±‚å¼ºåŒ–å­¦ä¹ æ¶æ„

```
é«˜å±‚ç­–ç•¥ (High-Level Policy)
â”œâ”€â”€ åŒºåŸŸåˆ†é…å†³ç­–
â”œâ”€â”€ åä½œæ¨¡å¼é€‰æ‹©  
â”œâ”€â”€ ä»»åŠ¡ä¼˜å…ˆçº§è§„åˆ’
â””â”€â”€ å…¨å±€çŠ¶æ€ç›‘æ§

ä½å±‚ç­–ç•¥ (Low-Level Policy)  
â”œâ”€â”€ è·¯å¾„è§„åˆ’æ‰§è¡Œ
â”œâ”€â”€ é£è¡Œæ§åˆ¶æŒ‡ä»¤
â”œâ”€â”€ éšœç¢ç‰©é¿å…
â””â”€â”€ å±€éƒ¨çŠ¶æ€å“åº”
```

### ç³»ç»Ÿç»„ä»¶

1. **å¤šæ— äººæœºç¯å¢ƒ (MultiDroneEnvironment)**
   - ä»¿çœŸç‰©ç†ç¯å¢ƒ
   - çŠ¶æ€ç©ºé—´ç®¡ç†
   - å¥–åŠ±å‡½æ•°è®¾è®¡
   - ç¢°æ’æ£€æµ‹

2. **åˆ†å±‚æ§åˆ¶å™¨ (HierarchicalController)**
   - é«˜ä½å±‚ç­–ç•¥åè°ƒ
   - ç›®æ ‡åˆ†è§£ä¸ä¼ é€’
   - åä½œæœºåˆ¶å®ç°

3. **ç­–ç•¥ç½‘ç»œ (Policy Networks)**
   - é«˜å±‚ç­–ç•¥: æ³¨æ„åŠ›æœºåˆ¶ + å…¨è¿æ¥å±‚
   - ä½å±‚ç­–ç•¥: LSTM + CNN + èåˆç½‘ç»œ

4. **è®­ç»ƒæ¡†æ¶ (Training Framework)**
   - PPOç®—æ³•å®ç°
   - å¤šæ™ºèƒ½ä½“æ”¯æŒ
   - åˆ†å¸ƒå¼è®­ç»ƒ

## âš™ï¸ é…ç½®è¯´æ˜

### ä¸»è¦é…ç½®æ–‡ä»¶: `multi_drone_training_config.yaml`

```yaml
environment:
  num_drones: 3              # æ— äººæœºæ•°é‡
  map_dimensions:
    width: 100               # åœ°å›¾å®½åº¦
    height: 100              # åœ°å›¾é«˜åº¦
  max_episode_steps: 1000    # æœ€å¤§æ­¥æ•°

hierarchical_rl:
  high_level:
    decision_frequency: 10   # é«˜å±‚å†³ç­–é¢‘ç‡
    action_space_size: 64    # åŠ¨ä½œç©ºé—´å¤§å°
  
  low_level:
    control_frequency: 1     # ä½å±‚æ§åˆ¶é¢‘ç‡
    action_space: [4]        # è¿ç»­åŠ¨ä½œç»´åº¦

ppo_config:
  learning_rate: 3e-4        # å­¦ä¹ ç‡
  train_batch_size: 4000     # è®­ç»ƒæ‰¹æ¬¡å¤§å°
  num_sgd_iter: 10          # SGDè¿­ä»£æ¬¡æ•°

parallel_training:
  num_gpus: 1               # GPUæ•°é‡
  num_workers: 4            # å·¥ä½œè¿›ç¨‹æ•°
```

## ğŸ“ˆ è®­ç»ƒç›‘æ§

### å…³é”®æŒ‡æ ‡
- **è¦†ç›–ç‡ (Coverage Ratio)**: åŒºåŸŸè¦†ç›–çš„ç™¾åˆ†æ¯”
- **åä½œæ•ˆç‡ (Collaboration Score)**: æ— äººæœºé—´åä½œçš„æœ‰æ•ˆæ€§
- **ä»»åŠ¡å®Œæˆæ—¶é—´ (Completion Time)**: è¾¾åˆ°ç›®æ ‡è¦†ç›–ç‡çš„æ—¶é—´
- **ç¢°æ’ç‡ (Collision Rate)**: æ— äººæœºç¢°æ’çš„é¢‘ç‡
- **èƒ½è€—æ•ˆç‡ (Energy Efficiency)**: å•ä½èƒ½è€—çš„è¦†ç›–æ•ˆæœ

### å¯è§†åŒ–å·¥å…·
```bash
# è®­ç»ƒæ›²çº¿å¯è§†åŒ–
python evaluation_visualization.py --mode visualize

# å®éªŒç»“æœåˆ†æ
python evaluation_visualization.py --mode analyze --results_dir ./results

# ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
python evaluation_visualization.py --mode evaluate --model best_model.pkl
```

## ğŸ”§ é«˜çº§é…ç½®

### è¯¾ç¨‹å­¦ä¹ 
ç³»ç»Ÿæ”¯æŒæ¸è¿›å¼è®­ç»ƒï¼Œä»ç®€å•åˆ°å¤æ‚ï¼š

1. **åŸºç¡€è¦†ç›–é˜¶æ®µ**: å­¦ä¹ åŸºæœ¬çš„åŒºåŸŸè¦†ç›–
2. **åä½œé˜¶æ®µ**: å­¦ä¹ å¤šæ— äººæœºåè°ƒ
3. **é«˜çº§ä»»åŠ¡é˜¶æ®µ**: å¤„ç†å¤æ‚ç¯å¢ƒå’ŒåŠ¨æ€ç›®æ ‡

### è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°
```python
def custom_reward_function(self, drone_id: int) -> float:
    state = self.drone_states[drone_id]
    reward = 0.0
    
    # è¦†ç›–å¥–åŠ±
    coverage_bonus = self.coverage_map.get_coverage_ratio() * 10.0
    
    # åä½œå¥–åŠ±
    collaboration_bonus = self._calculate_collaboration_reward(drone_id)
    
    # è‡ªå®šä¹‰å¥–åŠ±é¡¹
    # ...
    
    return reward
```

### å¤šç¯å¢ƒæ”¯æŒ
- **å¼€æ”¾ç¯å¢ƒ**: æ— éšœç¢ç‰©çš„ç®€å•ç¯å¢ƒ
- **éšœç¢ç‰©ç¯å¢ƒ**: åŒ…å«é™æ€éšœç¢ç‰©
- **åŠ¨æ€ç¯å¢ƒ**: ç§»åŠ¨éšœç¢ç‰©å’ŒåŠ¨æ€ç›®æ ‡
- **é€šä¿¡å—é™ç¯å¢ƒ**: æ¨¡æ‹Ÿå®é™…é€šä¿¡é™åˆ¶

## ğŸš ROSé›†æˆ

### Gazeboä»¿çœŸé›†æˆ
```bash
# å¯åŠ¨Gazeboä»¿çœŸ
roslaunch multi_drone_gazebo multi_drone_world.launch

# å¯åŠ¨å¼ºåŒ–å­¦ä¹ èŠ‚ç‚¹
python quick_start.py --mode train --config configs/ros_config.yaml
```

### å®æœºéƒ¨ç½²
```bash
# è¿æ¥å®é™…æ— äººæœº
export ROS_MASTER_URI=http://drone_computer:11311

# è¿è¡Œè®­ç»ƒå¥½çš„ç­–ç•¥
python deploy_real_drones.py --model checkpoints/best_model.pkl
```

## ğŸ“Š å®éªŒç»“æœ

### åŸºå‡†æµ‹è¯•ç»“æœ

| æ–¹æ³• | è¦†ç›–ç‡ | å®Œæˆæ—¶é—´ | ç¢°æ’ç‡ | åä½œåˆ†æ•° |
|------|--------|----------|--------|----------|
| åŸºäºè§„åˆ™ | 78.5% | 850s | 12.3% | 0.65 |
| ä¼ ç»ŸRL | 85.2% | 720s | 8.7% | 0.72 |
| **åˆ†å±‚RL (æœ¬æ–¹æ³•)** | **92.8%** | **580s** | **3.2%** | **0.89** |

### æ‰©å±•æ€§æµ‹è¯•
- âœ… 3-7æ— äººæœº: æ€§èƒ½ç¨³å®š
- âœ… å¤§è§„æ¨¡åœ°å›¾: 100x100 â†’ 500x500
- âœ… å¤æ‚ç¯å¢ƒ: å¤šéšœç¢ç‰©ç¯å¢ƒé€‚åº”è‰¯å¥½

## ğŸ› å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒè¿‡ç¨‹ä¸­GPUå†…å­˜ä¸è¶³
```bash
# å‡å°‘æ‰¹æ¬¡å¤§å°
train_batch_size: 2000  # é»˜è®¤4000

# å‡å°‘å·¥ä½œè¿›ç¨‹
num_workers: 2  # é»˜è®¤4
```

### Q2: æ”¶æ•›é€Ÿåº¦æ…¢
```bash
# å¢åŠ å­¦ä¹ ç‡
learning_rate: 5e-4  # é»˜è®¤3e-4

# å¯ç”¨è¯¾ç¨‹å­¦ä¹ 
curriculum_learning:
  enabled: true
```

### Q3: æ— äººæœºé¢‘ç¹ç¢°æ’
```bash
# å¢åŠ ç¢°æ’æƒ©ç½š
collision_penalty: -50.0  # é»˜è®¤-20.0

# è°ƒæ•´å®‰å…¨è·ç¦»
min_safe_distance: 3.0  # é»˜è®¤2.0
```

## ğŸ”„ ç‰ˆæœ¬æ›´æ–°

### v1.0.0 (å½“å‰)
- âœ… åŸºç¡€åˆ†å±‚å¼ºåŒ–å­¦ä¹ æ¶æ„
- âœ… å¤šæ— äººæœºåä½œæ”¯æŒ
- âœ… GPUå¹¶è¡Œè®­ç»ƒ
- âœ… å®æ—¶å¯è§†åŒ–

### v1.1.0 (è®¡åˆ’ä¸­)
- ğŸ”„ å¢å¼ºç°å®ç¯å¢ƒé€‚åº”
- ğŸ”„ æ›´å¤šåä½œç­–ç•¥
- ğŸ”„ æ€§èƒ½ä¼˜åŒ–

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç å’Œæ”¹è¿›å»ºè®®ï¼

1. Forké¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯: `git checkout -b feature/amazing-feature`
3. æäº¤æ›´æ”¹: `git commit -m 'Add amazing feature'`
4. æ¨é€åˆ†æ”¯: `git push origin feature/amazing-feature`
5. æäº¤Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ“ è”ç³»æ–¹å¼

- **é‚®ç®±**: guowei_ni@bit.edu.cn
- **é¡¹ç›®é“¾æ¥**: https://github.com/your-username/multi-drone-hrl
- **è®ºæ–‡**: [Multi-Agent Hierarchical Reinforcement Learning for Drone Swarm Exploration](link-to-paper)

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®çš„æ”¯æŒï¼š
- [Ray/RLlib](https://github.com/ray-project/ray)
- [OpenAI Gym](https://github.com/openai/gym)
- [PX4 Autopilot](https://github.com/PX4/PX4-Autopilot)
- [Gazebo](http://gazebosim.org/)

---

**å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªâ­ï¸ï¼**
